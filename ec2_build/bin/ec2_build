#!/usr/bin/env python
# (c) Copyright 2009 Cloudera, Inc.
__usage = """
   --staging | -s <dir>   Staging directory under /mnt/internalstaging.
                          (default: cdh3-staging)
   --staging-host <host>  Host to use for scp'ing resulting bits to staging.
                          (default: ubuntu64-10-10-slave.hal.cloudera.com)
   --key | -k  <key>      SSH key to allow connection to build slave instances
                          (default: current user name)

   --groups | -g <group>  EC2 Access Groups, comma-separated, to use on build
                          slaves
                          (default: cloudera, <username>)

   --dir | -d <dir>       Build products directory where we find source debs and rpms
   --tag | -t <release>   Choose CDH release (eg 'cdh2' or 'cdh3')
   --type <rpm|deb>       Only rebuild RPMs/debs
   --distro <distro>      Only build on given distro (eg centos5)
   --arch <arch>          Only build slaves of given arch (eg amd64)
   --dry-run | -n         Don't actually take any actions - just print out what
                          would normally happen

   --packages | -p <pkg>  Select package(s) to build may be listed multiple times
   --build_id <build_id>  Override the default build id
"""

class TimeoutException(Exception):
  pass

# Sanity check:
#
# DEBIAN_DISTROS: lenny, squeeze, etc.
# DEBIAN_SUITES: stable, testing
# SUITE: $DEBIAN_DISTRO-$DEBIAN_SUITE, $DEBIAN_DISTRO-testing
# CDH_RELEASE: cdh1, cdh2
# CODENAME: $DEBIAN_DISTRO-$CDH_RELEASE
# RELEASE: a build with version info hadoop-0.20_0.20.0+69+desktop.49-1cdh~intrepid-cdh2_i386

import boto
import datetime
import logging
import glob
import md5
from optparse import OptionParser
import os
import os.path
import sys
import re
import shutil
import time
import deb_util
import tempfile
from ec2_constants import AMIS, BUILD_INSTANCE_TYPES, DEFAULT_BUILD_MACHINES, STAGING_ROOT, STAGING_URL_ROOT, INTERIM_STAGING
from threading import Thread
import cloudera.utils
import cloudera.aws.ec2

# Expected location of build_[deb,rpm.sh]
SCRIPT_DIR = os.path.realpath(os.path.dirname(sys.argv[0]))

# Default codename (needs to be bumped with every CDH release)
DEFAULT_CDH_RELEASE = 'cdh2'

# Expected localtion of directories with sdebs and srpms
DEFAULT_BUILD_PRODUCTS_BASE = os.path.abspath(os.path.join(os.path.dirname(__file__), "../..", "output"))

# User running the script
try:
  USERNAME = os.getlogin()
except:
  USERNAME = 'build'

POSSIBLE_PACKAGES = [ 'hadoop18', 'hadoop20', 'pig', 'hive' , 'zookeeper','hbase', 'sqoop', 'flume', 'oozie', 'oozie-client', 'whirr', 'hadoop-snappy' ]
DEFAULT_PACKAGES = ['hadoop20']
# Build ID

# Directory in S3_BUCKET to put files
FILECACHE_S3="file-cache"

# How long should manifests be valid for
EXPIRATION=60*60*24*7 # 7days

# Shell scripts to run to perform builds
BUILD_DEB=file(SCRIPT_DIR + "/build_deb.sh").read()
BUILD_RPM=file(SCRIPT_DIR + "/build_rpm.sh").read()

# These values are actually the entire shell script contents, which
# we need to pass through boto
BUILD_SCRIPTS = {
  'deb': BUILD_DEB,
  'rpm': BUILD_RPM,
  }

#XXX Should be in lib/cloudera/constants
STATIC_SLAVES = {
	('centos5', 'x86'):    ('root', 'centos32-5-5-slave.hal.cloudera.com',   '../conf/static_vm_key'),
	('centos5', 'amd64'):  ('root', 'centos64-5-5-slave.hal.cloudera.com',   '../conf/static_vm_key'),
	('rhel6',   'amd64'):  ('root', 'rhel64-6-0-slave.hal.cloudera.com',     '../conf/static_vm_key'),
	('sles11',  'amd64'):  ('root', 'sles64-11-slave.hal.cloudera.com',      '../conf/static_vm_key'),
	('squeeze', 'x86'):    ('root', 'debian32-6-0-slave.hal.cloudera.com',   '../conf/static_vm_key'),
	('squeeze', 'amd64'):  ('root', 'debian64-6-0-slave.hal.cloudera.com',   '../conf/static_vm_key'),
	('lenny', 'x86'):    ('root', 'debian32-5-0-slave.hal.cloudera.com',   '../conf/static_vm_key'),
	('lenny', 'amd64'):  ('root', 'debian64-5-0-slave.hal.cloudera.com',   '../conf/static_vm_key'),
	('lucid',   'x86'):    ('root', 'ubuntu32-10-04-slave.hal.cloudera.com', '../conf/static_vm_key'),
	('lucid',   'amd64'):  ('root', 'ubuntu64-10-04-slave.hal.cloudera.com', '../conf/static_vm_key'),
	('maverick', 'x86'):   ('root', 'ubuntu32-10-10-slave.hal.cloudera.com', '../conf/static_vm_key'),
	('maverick', 'amd64'): ('root', 'ubuntu64-10-10-slave.hal.cloudera.com', '../conf/static_vm_key')
}

#XXX Should be in lib/cloudera/constants
def user_hostname_key_options(os_distro, arch):
  return STATIC_SLAVES[(os_distro, arch)]

#XXX Should be in cloudera/utils
class mylogger:
  def info(self, message):
    print message

#XXX Separate module
class BuildWorker(Thread):

  # Strict host key checking is deactivated because some instances may reuse the same ip (from a precedent run)
  # and then scare ssh
  # ServerAliveInterval is set so as to not loose connection with a quiet and slow remote instance
  # -ttt will force pseudo-tty allocation and avoid some issues where the session would hang because of the lack of tty
  SSH_OPTIONS = ['-o StrictHostKeyChecking=no', '-o ServerAliveInterval=120']

  # Sudo command
  SUDO_CMD = 'sudo'


  def __init__ (self, build_id, build_type, os_distro, arch, build_script):
    Thread.__init__(self)
    self.build_id = build_id
    self.build_type = build_type
    self.os_distro = os_distro
    self.arch = arch
    self.build_script = build_script
    self.returncode = None


  def start_logging(self):
    '''
    Start logging.
    Generate log filename and open file handle
    '''

    # Define logger
    self.logger = logging.getLogger("%s"%('_'.join([self.build_type, self.os_distro, self.arch])))

    # Set logger level
    self.logger.setLevel(logging.INFO)

    log_handler = logging.StreamHandler()

    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    log_handler.setFormatter(formatter)

    self.logger.addHandler(log_handler)


  def copy_build_script(self, build_script):
    temp_dir = tempfile.mkdtemp()

    build_script_filename = "%s-%s-%s-%s.sh" % (self.build_id,
                                                  self.build_type,
                                                  self.os_distro,
                                                  self.arch)
 
    build_file_path = os.path.join(temp_dir, build_script_filename)

    build_file = open(build_file_path, 'w')
    build_file.write(build_script)
    build_file.close()



    (user, hostname, key) = user_hostname_key_options(self.os_distro, self.arch)
    scp = cloudera.utils.SCP(user, hostname, key, self.SSH_OPTIONS)
    scp.set_logger(self.logger)

    scp.copy(build_file_path, '~/')

    shutil.rmtree(temp_dir)    

    return build_script_filename

 
  def do_build(self, build_script):
    '''
    Execute scripts on remote instance
    '''

    build_script_filename = self.copy_build_script(build_script)

    ssh_options = self.SSH_OPTIONS
    ssh_options.append('-ttt')

    # Setup a ssh connection
    (user, hostname, key) = user_hostname_key_options(self.os_distro, self.arch)
    ssh = cloudera.utils.SSH(user, hostname, key, ssh_options)

    # Prepare ssh command to be run
    cmd_remote = ''
    if not self.os_distro in cloudera.aws.ec2.distributions_without_sudo() :
      cmd_remote = self.SUDO_CMD + ' ' + cmd_remote

    # Ensure it is executable and then execute it
    return_code = ssh.execute('chmod', ['u+x', build_script_filename])
    return_code = ssh.execute(cmd_remote + './' + build_script_filename, [])

    # Third we remove it
    return_code = ssh.execute('rm', ['-fv', build_script_filename])

    self.returncode = return_code

    return self.returncode


  def run(self):

    self.start_logging()
    self.logger.info("Starting thread for (%s, %s, %s)"%(self.build_type, self.os_distro, self.arch))

    self.do_build(self.build_script)




def get_build_product_dir(cdh_release):
  return os.path.join(DEFAULT_BUILD_PRODUCTS_BASE,
                      re.match('cdh\d+', cdh_release).group())

class Options:


  def __init__(self):
    # Bucket to store source RPMs/debs in
    self.STAGING = 'cdh3-build'
    self.STAGING_HOST = 'ubuntu64-10-10-slave.hal.cloudera.com'
    self.BUILD_ID = "%s-%s" % (USERNAME, datetime.datetime.now().strftime("%Y%m%d_%H%M%S"))
    self.EC2_KEY_NAME = USERNAME
    self.EMAIL_ADDRESS = "%s@cloudera.com" % (USERNAME)
    self.EC2_GROUPS=['cloudera', USERNAME ]
    self.BUILD_MACHINES = DEFAULT_BUILD_MACHINES
    self.CDH_RELEASE=DEFAULT_CDH_RELEASE
    self.BUILD_PRODUCTS_DIR=get_build_product_dir(DEFAULT_CDH_RELEASE)
    self.DRY_RUN = False
    self.INTERACTIVE = False
    self.WAIT = False
    self.TIMEOUT = -1
    # Default to building hadoop
    self.PACKAGES = DEFAULT_PACKAGES
  pass


def parse_args():
  """ Parse command line arguments into globals. """

  ret_opts = Options()

  op = OptionParser(usage = __usage)
  #  op.add_option('-b', '--bucket')
  op.add_option('-s', '--staging')
  op.add_option('--staging-host')
  op.add_option('-k', '--key')
  op.add_option('-e', '--email')
  op.add_option('-g', '--groups')
  op.add_option('-d', '--dir')
  op.add_option('-t', '--tag')
  op.add_option('--type', action='append')
  op.add_option('--distro', action='append')
  op.add_option('--arch', action='append')
  op.add_option('--build_id')
  op.add_option('-n', '--dry-run', action='store_true')
  op.add_option("--timeout", metavar="TIMEOUT", help="Kill off instances if we run for to long in minutes")
  op.add_option('-p', '--packages', action='append', choices=POSSIBLE_PACKAGES)
  op.add_option("-i", '--interactive', action="store_true")
  op.add_option('-w', '--wait', action="store_true")

  opts, args = op.parse_args()

  if len(args):
    op.print_usage()
    raise Exception("Unhandled args: %s" % repr(args))

  if opts.groups:
    ret_opts.EC2_GROUPS = opts.groups.split(',')

  if opts.arch:
    ret_opts.BUILD_MACHINES = [(type,distro,arch ) for (type, distro, arch) in ret_opts.BUILD_MACHINES if arch in opts.arch  ]

  if opts.distro:
    ret_opts.BUILD_MACHINES = [(type,distro,arch ) for (type, distro, arch) in ret_opts.BUILD_MACHINES if distro in opts.distro ]

  if opts.type:
    ret_opts.BUILD_MACHINES = [(type,distro,arch ) for (type, distro, arch) in ret_opts.BUILD_MACHINES if type in opts.type  ]

  ret_opts.DRY_RUN = opts.dry_run

  ret_opts.INTERACTIVE = opts.interactive

  ret_opts.WAIT = opts.wait

  #if opts.bucket:
  #ret_opts.S3_BUCKET = opts.bucket

  if opts.staging:
    ret_opts.STAGING = opts.staging

  if opts.staging_host:
    ret_opts.STAGING_HOST = opts.staging_host
  
  if opts.build_id:
    ret_opts.BUILD_ID = opts.build_id

  if opts.key:
    ret_opts.EC2_KEY_NAME = opts.key

  if opts.email:
    ret_opts.EMAIL_ADDRESS = opts.email

  if opts.packages:
    ret_opts.PACKAGES = opts.packages

  if opts.timeout:
    ret_opts.TIMEOUT = int(float(opts.timeout)*60)

  if opts.tag:
    ret_opts.CDH_RELEASE = opts.tag

  if opts.dir:
    ret_opts.BUILD_PRODUCTS_DIR = opts.dir
  else:
    ret_opts.BUILD_PRODUCTS_DIR = get_build_product_dir(ret_opts.CDH_RELEASE)


  return ret_opts


def md5file(filename):
  """ Return the hex digest of a file without loading it all into memory. """
  fh = file(filename)
  digest = md5.new()
  while 1:
    buf = fh.read(4096)
    if buf == "":
      break
    digest.update(buf)
  fh.close()
  return digest.hexdigest()


def progressbar(bytes_done, total_bytes):
  """ Display a progress bar for boto file upload callback """
  print "Sent % 5d/%d KB" % (bytes_done/1024, total_bytes/1024),

  width = 60
  bar_len = (width * bytes_done / total_bytes)
  print "[" + ("=" * bar_len) + ">" + (" " * (width - bar_len - 1)) + "]",
  print "\r",
  sys.stdout.flush()


def satisfy_in_cache(staging_dir, path):
  """
  Ensure that the file at path 'path' is present in the file cache
  in bucket 'bucket'. Presence is determined by the md5sum of the
  file. If it is not present, uploads it.

  @param bucket an S3Bucket instance
  @param path a path on the local filesystem
  """
  checksum = md5file(path)

  print >>sys.stderr, "Trying to satisfy %s from cache..." % os.path.basename(path)
  dest_file = os.path.join(staging_dir, os.path.basename(path))

  if os.path.isfile(dest_file):
    if md5file(dest_file) != checksum:
      print >>sys.stderr, "File exists, but with incorrect contents. Recopying."
      shutil.copy(path, dest_file)
    else:
      print >>sys.stderr, "File exists and matches checksum."
  else:
    print >>sys.stderr, "File does not exist. Copying."
    shutil.copy(path, dest_file)

  return (checksum, "%s/%s" % (STAGING_URL_ROOT, os.path.relpath(dest_file, STAGING_ROOT)))


def upload_files_and_manifest(options, package_files):
  """
  Upload all of the required files as well as a manifest.txt file into
  the BUILD_ID dir on S3.

  @param package_files A dictionary keyed by the package to be build. Each key's value is dictionary keyed for deb|rpm that have lists of files needed to build the package
  """
  staging_dir = os.path.join(STAGING_ROOT, options.STAGING, options.BUILD_ID, "source")

  if not os.path.isdir(staging_dir):
    try:
      os.makedirs(staging_dir)
    except OSError as exc:
      if exc.errno == errno.EEXIST:
        pass
      else:
        print "Unable to create staging directory %s:" % (staging_dir, )
        raise
      
  build_dir = os.path.join("build", options.BUILD_ID)

  manifest_list = []

  for package in package_files:
    files = package_files[package]
    for package_format, paths in files.iteritems():
      for path in paths:
        (checksum, url) = satisfy_in_cache(staging_dir, path)
        manifest_list.append(('-'.join([package, package_format]), os.path.basename(path), checksum, url))
  manifest = "\n".join(
    ["\t".join(el) for el in manifest_list])

  if not options.DRY_RUN:
    man_path = os.path.join(STAGING_ROOT, options.STAGING, options.BUILD_ID, "manifest.txt")
    man_file = open(man_path, 'w')
    man_file.write(manifest)
    man_file.close()

    return "%s/%s" % (STAGING_URL_ROOT, os.path.relpath(man_path, STAGING_ROOT))
  else:
    return "<manifest not uploaded - dry run>"


def main():

  options = parse_args()

  # Figure out what packages need to built
  package_files = {}
  for package in options.PACKAGES:
    package_files[package] = {
      'deb': deb_util.find_source_deb_files(os.path.join(options.BUILD_PRODUCTS_DIR, package)),
      'rpm': glob.glob(os.path.join(options.BUILD_PRODUCTS_DIR, package, "*.src.rpm")),
    }

    changelog = glob.glob(os.path.join(options.BUILD_PRODUCTS_DIR, package, "*-changes.log"))
    relnotes = glob.glob(os.path.join(options.BUILD_PRODUCTS_DIR, package, "*.releasenotes.html"))

    sources_all = glob.glob(os.path.join(options.BUILD_PRODUCTS_DIR, package, "*.tar.gz"))
    sources = []
    for source in sources_all:
      sources.append(source)
    if len(sources) == 0:
      print "ERROR: No tarball found"
      sys.exit(-1)

    sources = filter(lambda filename: re.match('^.*-CDH[0-9BU]+(?:-SNAPSHOT)?\.tar\.gz$', filename, flags=re.IGNORECASE), sources)

    for arch in ['deb', 'rpm']:
      package_files[package][arch].extend(sources)
      package_files[package][arch].extend(relnotes)
      package_files[package][arch].extend(changelog)

  manifest_url = upload_files_and_manifest(options, package_files)
  print manifest_url
  time.sleep(35)

  ec2 = boto.connect_ec2()

  instances = []
  for build_type, os_distro, arch in options.BUILD_MACHINES:
    instance_type = BUILD_INSTANCE_TYPES[arch]
    start_script = BUILD_SCRIPTS[build_type]

    subs = {
      'build_id': options.BUILD_ID,
      'username': USERNAME,
      'email_address': options.EMAIL_ADDRESS,
      'os_distro': os_distro,
      'cdh_release': options.CDH_RELEASE,
      'interactive': str(options.INTERACTIVE),
      'manifest_url': manifest_url,
      'packages': ' '.join(options.PACKAGES),
      'staging': os.path.join(STAGING_ROOT, options.STAGING),
      'staging_url': "%s/%s" % (STAGING_URL_ROOT, options.STAGING, ),
      'staging_host': options.STAGING_HOST,
      'interim_staging': INTERIM_STAGING,
      'aws_access_key_id': ec2.aws_access_key_id,
      'aws_secret_access_key': ec2.aws_secret_access_key,
      }

    subbed_script = start_script.replace(
      "##SUBSTITUTE_VARS##",
      """
      BUILD_ID='%(build_id)s'
      CDH_RELEASE='%(cdh_release)s'
      INTERACTIVE='%(interactive)s'
      BUILD_USER='%(username)s'
      EMAIL_ADDRESS='%(email_address)s'
      CODENAME='%(os_distro)s-%(cdh_release)s'
      MANIFEST_URL='%(manifest_url)s'
      PACKAGES='%(packages)s'
      STAGING='%(staging)s'
      STAGING_URL='%(staging_url)s'
      STAGING_HOST='%(staging_host)s'
      INTERIM_STAGING='%(interim_staging)s'
      AWS_ACCESS_KEY_ID='%(aws_access_key_id)s'
      AWS_SECRET_ACCESS_KEY='%(aws_secret_access_key)s'
      """ % subs)

    print "Connecting %s-%s build slave..." % (os_distro, arch)
    if not options.DRY_RUN:
      worker = BuildWorker(options.BUILD_ID,
                            build_type,
                            os_distro,
                            arch,
                            subbed_script)
      worker.start()

      instances.append(worker)
      #reservation = image.run(
      #  key_name=options.EC2_KEY_NAME,
      #  security_groups=options.EC2_GROUPS,
  #      user_data=subbed_script,
   #     instance_type=instance_type)
    else:
      print "   [dry run: not starting]"
  try:
    print "Waiting for instances to terminate..."

    for instance in instances:
      instance.join()

    print "Instances have terminated..."
    #    print "Expect results at s3://%s/build/%s/" % (options.S3_BUCKET, options.BUILD_ID)
    #print "To update apt repo after build is finished:"
    #print "  update_repo.sh %s %s" % (options.S3_BUCKET, options.BUILD_ID)

  except KeyboardInterrupt:
    print "Interrupting cleaning up old instances"
    for instance in instances:
      print "Stopping instance: %s " % instance
      instance.terminate()
  except TimeoutException:
    print "Interrupting cleaning up old instances"
    for instance in instances:
      print "Stopping instance: %s " % instance
      instance.terminate()

if __name__ == "__main__":
  main()
