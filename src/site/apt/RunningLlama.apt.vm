~~ Licensed under the Apache License, Version 2.0 (the "License");
~~ you may not use this file except in compliance with the License.
~~ You may obtain a copy of the License at
~~
~~ http://www.apache.org/licenses/LICENSE-2.0
~~
~~ Unless required by applicable law or agreed to in writing, software
~~ distributed under the License is distributed on an "AS IS" BASIS,
~~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
~~ See the License for the specific language governing permissions and
~~ limitations under the License.

  ---
  Llama, Running
  ---
  ---
  ${maven.build.timestamp}

Running Llama

%{toc|section=1|fromDepth=2}

* Llama Application Master

** Install Llama AM

  Build or download, and expand the Llama distribution tarball,
  <<<llama-${project.version}.tar.gz>>>.

  Llama requires a local Hadoop client installed and configured to access the 
  Hadoop cluster.    
    
** Llama AM Configuration

  Within Llama root directory:
  
    * Llama startup configuration: <<<libexec/llama-env.sh>>>.
  
    * Llama server configuration: 
    <<<{{{./llama-site.html}conf/llama-site.xml}}>>> (changes take effect on 
    re-start).
  
    * Llama server logging: 
    <<<{{{./llama-log4j.properties}conf/llama-log4j.properties}}>>> (changes 
    take effect within 1 second).

  <<NOTE:>> These files have all configuration properties with their default 
  values.
    
** Hadoop Yarn Configuration for Llama AM (Required)
    
  The user running LlamaAM must be configured in Hadoop as a proxy user for 
  itself.
  
  Without Hadoop security enabled, the user running the LlamaAM server is Unix 
  user starting the LlamaAM server.
  
  With Hadoop security enabled, the user running the LlamaAM server is the 
  short name of the Kerberos Principal used by the LlamaAM server (i.e. 
  for a <<<llama/HOSTNAME>>> Kerberos principal, the short name is <<<llama>>>).
  
  Hadoop's <<<core-site.xml>>> must include the following 2 configuration
  properties:
  
+----+
  <property>
    <name>hadoop.proxyuser.#LLAMAUSER#.hosts</name>
    <value>#HOSTNAME_RUNNING_LLAMA#</value>
  </property>
  <property>
    <name>hadoop.proxyuser.#LLAMAUSER#.groups</name>
    <value>#GROUP_LLAMA_USER_BELONGS_TO#</value>
  </property>
+----+
  
  For example if the user running the LlamaAM server is <<<llama>>>, the LlamaAM
  server is running in host <<<foo.com>>> and the <<<llama>>> user belongs 
  to the <<<llamagroup>>> group, the 2 configuration properties would be:
  
+----+
  <property>
    <name>hadoop.proxyuser.llama.hosts</name>
    <value>foo.com</value>
  </property>
  <property>
    <name>hadoop.proxyuser.llama.groups</name>
    <value>llamagroup</value>
  </property>
+----+

  <<NOTE:>> For development and testing, if the values are set to <<<*>>> the 
  LlamaAM server can be running from any host and there is no need to create a 
  <<<llamagroup>>>.
  
** Run Llama AM

  To start Llama:
  
+----+
$ bin/llama
2013-08-02 06:57:32,743 INFO  Main - -----------------------------------------------------------------
2013-08-02 06:57:32,746 INFO  Main -   Java runtime version : 1.6.0_51-b11-457-11M4509
2013-08-02 06:57:32,747 INFO  Main -   Llama version        : 1.0.0-cdh5.0.0-SNAPSHOT
2013-08-02 06:57:32,747 INFO  Main -   Llama built date     : 2013-08-02T13:43Z
2013-08-02 06:57:32,747 INFO  Main -   Llama built by       : tucu
2013-08-02 06:57:32,747 INFO  Main -   Llama revision       : ba875da60c9865cceb70c352eb062f4fd1dfa309
2013-08-02 06:57:32,784 INFO  Main -   Hadoop version       : 2.1.0-cdh5.0.0-SNAPSHOT
2013-08-02 06:57:32,784 INFO  Main - -----------------------------------------------------------------
2013-08-02 06:57:32,784 INFO  Main - Configuration directory: /Users/tucu/llama/conf
2013-08-02 06:57:32,878 INFO  Main - Server: com.cloudera.llama.am.LlamaAMServer
2013-08-02 06:57:32,879 INFO  Main - -----------------------------------------------------------------
2013-08-02 06:57:33,790 INFO  LlamaAMThriftServer - Server listening on: 0.0.0.0:15000
2013-08-02 06:57:33,790 INFO  LlamaAMThriftServer - Llama started!
+----+

  Llama will run in the foreground.

  To stop Llama do a <<<CTRL-C>>> on the terminal running llama or do a 
  <<<kill>>> on the PID, Llama will shutdown gracefully on a <<<SIGINT>>>:
  
+----+
...
2013-08-02 07:06:28,434 INFO  LlamaAMThriftServer - Llama started!
^C
2013-08-02 07:06:29,653 INFO  LlamaAMThriftServer - Llama shutdown!
$
+----+

** Security Configuration for Llama AM

  If configuring Llama with security Enabled (Thrift with Kerberos SASL) you 
  need a running KDC, a service keytab (<<<llama/HOSTNAME>>>) and the
  corresponding keytab file.
  
  The properties to configure in the <<<llama-site.xml>>> file are (shown with 
  default values):
  
    * llama.am.server.thrift.security=false
  
    * llama.am.server.thrift.kerberos.keytab.file=llama.keytab
  
    * llama.am.server.thrift.kerberos.server.principal.name=llama/_HOST
  
    * llama.am.server.thrift.kerberos.notification.principal.name=impala
  
  The <<<_HOST>>> in the principal name gets resolved to the canonical hostname
  of the machine where LlamaAM is running. To avoid misconfiguration problems, 
  use the actual hostname instead <<<_HOST>>>. The hostname used should match
  the hostname the server address resolves to. The server address is set in the
  <<<llama.am.server.thrift.address>>> configuration property (the port number
  will be ignored if present). 
  
  <<IMPORTANT:>> the default server address is <<<0.0.0.0>>>, if enabling 
  security the address should be changed to a fixed IP or (better) a hostname. 
  If set to a fixed IP, the hostname that IP resolves to must match the hostname 
  in the Kerberos service principal.
  
  If the path specified in <<<llama.am.server.thrift.kerberos.keytab.file>>> is
  a relative path, the keytab file will be expected in the Llama configuration 
  directory.

  When specifying the principal names use the short name only, do not include 
  the service hostname. The Thrift SASL implementation composes the complete 
  service principal name (<<<shortName>>>/<<<hostname>>>).

** HTTP JSON JMX Endpoint

  Llama AM exposes a HTTP JSON JMX endpoint (it uses Hadoop's HTTP JSON JMX
  servlet).

  The <<<llama.am.server.thrift.http.jmx.address>>> configuration property
  defines the address the JMX servlet is bound to, by default is
  <<<0.0.0.0:15001>>>.

  The JMX servlet is available at <<</jmx>>>, for example
  <<<http://localhost:15001/jmx>>>.

** Gang Scheduling Anti-Deadlock Detection

  Llama implements client side gang scheduling by waiting for all resources
  of a gang reservation to be granted before notifying Impala.

  To avoid deadlocks among multiple reservations waiting for resources held by
  each other, Llama implements the following anti-deadlock logic. If no new
  resources are allocated for all gang reservations in a configured amount of
  time, a back off policy is triggered. The backoff policy will transparently
  cancel random gang reservations until a configured percentage of canceled
  resources is reached. The canceled reservations will be backed off for a
  random delay between a configured minimum and maximum delay. Once the random
  elapses, the reservation will be automatically submitted.

  The anti-deadlock detection logic is completely transparent to Llama clients.

  The Llama configuration properties for anti-deadlock detection and their
  default values are

  * llama.am.gang.anti.deadlock.enabled = true

  * llama.am.gang.anti.deadlock.no.allocation.limit.ms = 30000

  * llama.am.gang.anti.deadlock.backoff.percent = 30

  * llama.am.gang.anti.deadlock.backoff.min.delay.ms = 10000

  * llama.am.gang.anti.deadlock.backoff.max.delay.ms = 30000

* Llama Node Manager Plugin

** Install Llama NM Plugin

  Expand the Llama TARBALL distribution files.

  The Llama installation has a <<<nodemanagerlib/>>> directory. The JARs within
  this directory must be added to the classpath of all NodeManagers in the Yarn
  cluster.

** Llama NM Plugin Configuration

  TBD

** Hadoop Yarn Configuration for Llama NM Plugin (Required)

  TBD

** Security Configuration for Llama NM Plugin

  TBD

* Notes on Thrift

  Llama Thrift server supports unframed transport only (per Impala requirement).
  Because of this Llama must use synchronous IO (<<<TThreadPoolServer>>>).
  
  Kerberos Thrift SASL is supported.
