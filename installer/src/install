#!/usr/bin/env python
#
# (c) Copyright 2008 Cloudera, Inc.
#
# Installation tool for Cloudera Hadoop Distribution
# main entry point
#
# Usage: install [options]
# Type "install --help" for full usage instructions
#
#

import os
import sys

import com.cloudera.distribution.arch as arch
from   com.cloudera.distribution.installerror import InstallError
import com.cloudera.distribution.installproperties as installproperties
import com.cloudera.distribution.manifest as manifest
import com.cloudera.distribution.remotemgr as remotemgr
import com.cloudera.util.output as output

# do this before doing anything else.
output.initLogging()

# use all args except program name
argv = sys.argv[1:]

# set up configuration, init stdout/stderr
properties = installproperties.InstallProperties()
output.attachOutputArgParser(properties)

installproperties.loadAllProperties(properties, argv)

output.setupConsole(properties)

# if we are here, then properties and argv parsing succeeded

# TODO: Install a log file as well
# TODO: Location should be configured by a command line arg.

# Where are we? Switch into installer's base dir
binName = sys.argv[0]
binDir = os.path.dirname(binName)
os.chdir(binDir)

# determine what architecture / platform we're running on.
archDetector = arch.getArchDetector()
archDetector.scan()
if archDetector.getPlatform() == arch.PLATFORM_UNKNOWN:
  output.printlnInfo("Warning: Could not determine linux platform")
  output.printlnInfo("This hampers my ability to determine if you "
      + "have the correct prerequisite")
  output.printlnInfo("packages installed.")

if archDetector.getArch() == arch.ARCH_UNKNOWN:
  # if we can't figure out the arch, then we disable allowing native
  # compression, because we don't want to enable in-Java compression by default
  # by mistake.
  output.printlnInfo("Warning: Could not determine system architecture")
  output.printlnInfo("This hampers my ability to install the correct libraries")
  output.printlnInfo("Disabling native compression libraries in MapReduce")
  properties.setProperty(ALLOW_NATIVE_COMPRESSION_KEY, False)

try:
  # Assemble installation plan from command line flags
  output.printlnDebug("Creating installation plan...")
  installPlan = manifest.createInstallPlan(properties)

  # Detect any prereqs that we cannot install:
  output.printlnInfo("Checking prerequisites for installation...")
  for tool in installPlan.getInstallItems():
    tool.precheck()

  output.printlnInfo("All necessary prerequisites were found.")

  output.printlnInfo("""
To set up Hadoop, we need to ask you a few basic questions about your
cluster. When possible, acceptable defaults are provided to you, which you
can select by pressing [enter].
""")

  for tool in installPlan.getInstallItems():
    tool.configure()

  # Any user input should have occurred above this line. From this point
  # forward, we only bail out because an underlying installation item
  # chokes -- this is out of the user's hands by here.

  # execute installation plan
  for tool in installPlan.getInstallItems():
    output.printlnInfo("Installing " + tool.getName())
    tool.install()

  # any steps to be performed per-tool after the whole system is together
  for tool in installPlan.getInstallItems():
    output.printlnInfo("Performing postinstall for " + tool.getName())
    tool.postInstall()

  # Perform automated deployment to additional machines
  # TODO: Unattended installation should only do this if DEPLOY_SLAVES_KEY
  # is true; interactive installation should prompt for whether/not to do this
  # in either case, only do this if we are in the "master" profile.
  remotemgr.deployRemotes()

  # Perform any verification steps that this all installed OK
  for tool in installPlan.getInstallItems():
    output.printlnInfo("Verifying installation of " + tool.getName())
    tool.verify()

except InstallError, ie:
  output.printlnError("An error occurred during the installation process:")
  output.printlnError(str(ie))
  otuput.printlnError("Installation has been aborted")
  sys.exit(1)

# TODO: Find the real hadoop start command
hadoopStartCmd = "foo/bar/baz/bin/start-all.sh"
output.printlnInfo( \
"""The Cloudera Hadoop Distribution installation process is complete! You
can start Hadoop by running:
$ %(hadoopStart)s

You can deploy on additional slaves by running:
TODO: Determine command to use to allow no-attend remote deploy""" %
    { "hadoopStart" : hadoopStartCmd })

# TODO: If did not do deployRemotes(), should inform the user that they
# need to run a remote deployment. (give them the command to do so)

# TODO: If there were warnings, list the follow-up actions that must be taken.

# TODO: Print the list of components installed and any other summary info

# TODO: If HADOOP_USER_KEY is set and this username does not exist on all nodes
# we should tell the user that they should create the account.

sys.exit(0)

